{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60a378d",
   "metadata": {},
   "source": [
    "Analyzes the 'thermo_detailed.txt' output files.\n",
    "\n",
    "This script:\n",
    "1.  Finds all 'thermo_detailed.txt' files.\n",
    "2.  Parses the data, separating cooling and heating ramps.\n",
    "3.  Uses the derivative method (d(PE)/dT) to find (Ms, Mf, As, Af).\n",
    "4.  Runs programmatic sanity checks on the results.\n",
    "5.  Saves a 4-panel plot for auditing/debugging.\n",
    "6.  Saves a 'transformation_summary.txt' with the key values AND\n",
    "    a clear success/failure flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.signal import savgol_filter\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "code-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "PROJECT_ROOT = Path(\"/home/rimuru/workspace\")\n",
    "INPUT_DATA_ROOT = PROJECT_ROOT / \"data\" / \"raw_output\"\n",
    "ANALYSIS_OUTPUT_ROOT = PROJECT_ROOT / \"data\" / \"analysis_output\"\n",
    "\n",
    "ANALYSIS_CONFIG = {\n",
    "    # Savitzky-Golay filter window length (must be odd)\n",
    "    # Larger window = more smoothing (good for noisy data)\n",
    "    \"WINDOW_LENGTH\": 51,\n",
    "    # Savitzky-Golay filter polynomial order (usually 2 or 3)\n",
    "    \"POLYORDER\": 3,\n",
    "    # Percentage of peak height to define start/end of transformation\n",
    "    # Smaller value = wider transformation range\n",
    "    \"THRESHOLD_PERCENT\": 0.05,  # 5%\n",
    "    \n",
    "    ### NEW ###\n",
    "    # Minimum signal-to-noise ratio for the derivative peak.\n",
    "    # A value > 5 is usually good. If you get warnings,\n",
    "    # try increasing WINDOW_LENGTH or lowering this threshold.\n",
    "    \"MIN_PEAK_SIGNIFICANCE\": 5.0 \n",
    "}\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads the thermo_detailed.txt file into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        header_line = \"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\"):\n",
    "                    header_line = line.strip().lstrip(\"# \").split()\n",
    "                    break\n",
    "        if not header_line:\n",
    "            raise ValueError(\"Could not parse header.\")\n",
    "            \n",
    "        df = pd.read_csv(\n",
    "            filepath,\n",
    "            sep='\\s+',\n",
    "            # delim_whitespace=True,\n",
    "            comment=\"#\",\n",
    "            names=header_line,\n",
    "            skiprows=1\n",
    "        )\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        return df.dropna()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\", file=sys.stderr)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {filepath}: {e}\", file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "code-split-cycles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cycles(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Splits the full dataframe into cooling and heating ramps.\n",
    "    Filters out equilibration steps by looking at the temperature derivative.\n",
    "    \"\"\"\n",
    "    df['dT'] = df['temp'].diff()\n",
    "    # A more robust filter to find the main ramp\n",
    "    cooling_df = df[df['dT'] < -1e-6].copy()\n",
    "    heating_df = df[df['dT'] > 1e-6].copy()\n",
    "    return cooling_df, heating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "code-analyze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transformation(\n",
    "    cycle_df: pd.DataFrame, \n",
    "    property_col: str = 'pe', \n",
    "    temp_col: str = 'temp'\n",
    ") -> (float, float, float, dict):\n",
    "    \"\"\"\n",
    "    Analyzes a single ramp (cooling or heating) to find\n",
    "    start, peak, and finish temperatures (e.g., Ms, M_peak, Mf).\n",
    "    \n",
    "    Returns: (T_start, T_peak, T_finish, analysis_data_dict)\n",
    "    \"\"\"\n",
    "    cfg = ANALYSIS_CONFIG\n",
    "    \n",
    "    cycle_df = cycle_df.sort_values(by=temp_col)\n",
    "    T = cycle_df[temp_col].values\n",
    "    P = cycle_df[property_col].values\n",
    "    \n",
    "    if len(T) < cfg[\"WINDOW_LENGTH\"]:\n",
    "        print(\n",
    "            f\"   [WARN] Not enough data points ({len(T)}) for \"\n",
    "            f\"smoothing window ({cfg['WINDOW_LENGTH']}). Skipping.\",\n",
    "            file=sys.stderr\n",
    "        )\n",
    "        return np.nan, np.nan, np.nan, {\"failed\": True}\n",
    "\n",
    "    try:\n",
    "        P_smooth = savgol_filter(\n",
    "            P, \n",
    "            window_length=cfg[\"WINDOW_LENGTH\"], \n",
    "            polyorder=cfg[\"POLYORDER\"]\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"   [WARN] Error during smoothing: {e}. Skipping.\", file=sys.stderr)\n",
    "        return np.nan, np.nan, np.nan, {\"failed\": True}\n",
    "\n",
    "    dPdT = np.gradient(P_smooth, T)\n",
    "    \n",
    "    dPdT_smooth = savgol_filter(\n",
    "        dPdT, \n",
    "        window_length=cfg[\"WINDOW_LENGTH\"], \n",
    "        polyorder=cfg[\"POLYORDER\"]\n",
    "    )\n",
    "    \n",
    "    # 5. Find the transformation peak (positive peak for both)\n",
    "    peak_idx = np.argmax(dPdT_smooth)\n",
    "    T_peak = T[peak_idx]\n",
    "    \n",
    "    # 6. Find start and finish temperatures\n",
    "    baseline_val = np.min(dPdT_smooth)\n",
    "    peak_height = dPdT_smooth[peak_idx] - baseline_val\n",
    "    threshold = baseline_val + cfg[\"THRESHOLD_PERCENT\"] * peak_height\n",
    "    \n",
    "    T_start, T_finish = np.nan, np.nan\n",
    "    try:\n",
    "        active_indices = np.where(dPdT_smooth > threshold)[0]\n",
    "        if len(active_indices) == 0:\n",
    "            raise ValueError(\"No transformation peak found above threshold.\")\n",
    "            \n",
    "        T_start = T[active_indices[0]]\n",
    "        T_finish = T[active_indices[-1]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   [WARN] Could not find T_start/T_finish: {e}\", file=sys.stderr)\n",
    "\n",
    "    ### NEW: Calculate metrics for sanity checks ###\n",
    "    # We define \"noise\" as the standard deviation of the *un-smoothed*\n",
    "    # derivative, which is a good measure of the data's \"jiggle\".\n",
    "    # A more robust noise measure: std of the residual\n",
    "    noise_level = np.std(dPdT - dPdT_smooth) \n",
    "    peak_significance = peak_height / noise_level if noise_level > 1e-9 else 0.0\n",
    "\n",
    "    analysis_data = {\n",
    "        \"T\": T,\n",
    "        \"P_smooth\": P_smooth,\n",
    "        \"dPdT_smooth\": dPdT_smooth,\n",
    "        \"threshold\": threshold,\n",
    "        \"peak_significance\": peak_significance,\n",
    "        \"failed\": False\n",
    "    }\n",
    "    \n",
    "    return T_start, T_peak, T_finish, analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "code-sanity-checks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW: Sanity Check Functions ###\n",
    "def run_sanity_checks(analysis: dict, errors: list) -> bool:\n",
    "    \"\"\"\n",
    "    Runs a series of automated checks on the analysis results.\n",
    "    Returns True if OK, False if any check fails.\n",
    "    Modifies the 'errors' list in-place.\n",
    "    \"\"\"\n",
    "    cfg = ANALYSIS_CONFIG\n",
    "    Ms, M_peak, Mf = analysis['cooling']['temps']\n",
    "    As, A_peak, Af = analysis['heating']['temps']\n",
    "    cool_data = analysis['cooling']['plot_data']\n",
    "    heat_data = analysis['heating']['plot_data']\n",
    "    \n",
    "    is_ok = True\n",
    "\n",
    "    # Check 1: Did the analysis run at all?\n",
    "    if cool_data.get(\"failed\", False) or heat_data.get(\"failed\", False):\n",
    "        errors.append(\"Analysis routine failed (e.g., not enough data).\")\n",
    "        is_ok = False\n",
    "        # Stop here, other checks will fail\n",
    "        return is_ok\n",
    "\n",
    "    # Check 2: Were all temperatures found?\n",
    "    temps = {'Ms': Ms, 'Mf': Mf, 'As': As, 'Af': Af}\n",
    "    for name, T in temps.items():\n",
    "        if np.isnan(T):\n",
    "            errors.append(f\"Could not determine '{name}' (result is NaN).\")\n",
    "            is_ok = False\n",
    "            \n",
    "    if not is_ok:\n",
    "        # Stop here, physical ordering checks will fail\n",
    "        return is_ok\n",
    "\n",
    "    # Check 3: Physical Ordering\n",
    "    if Ms <= Mf:\n",
    "        errors.append(f\"Physicality Error: Ms ({Ms:.1f} K) must be > Mf ({Mf:.1f} K).\")\n",
    "        is_ok = False\n",
    "    if Af <= As:\n",
    "        errors.append(f\"Physicality Error: Af ({Af:.1f} K) must be > As ({As:.1f} K).\")\n",
    "        is_ok = False\n",
    "    if As <= Mf:\n",
    "        errors.append(f\"Physicality Error: As ({As:.1f} K) must be > Mf ({Mf:.1f} K).\")\n",
    "        is_ok = False\n",
    "        \n",
    "    # Check 4: Peak Significance (Signal-to-Noise)\n",
    "    cool_sig = cool_data.get('peak_significance', 0)\n",
    "    heat_sig = heat_data.get('peak_significance', 0)\n",
    "    \n",
    "    if cool_sig < cfg[\"MIN_PEAK_SIGNIFICANCE\"]:\n",
    "        errors.append(\n",
    "            f\"Cooling peak is not significant (S/N: {cool_sig:.1f} \"\n",
    "            f\"< threshold: {cfg['MIN_PEAK_SIGNIFICANCE']}). \"\n",
    "            \"Data may be too noisy or smoothing is wrong.\"\n",
    "        )\n",
    "        is_ok = False\n",
    "        \n",
    "    if heat_sig < cfg[\"MIN_PEAK_SIGNIFICANCE\"]:\n",
    "        errors.append(\n",
    "            f\"Heating peak is not significant (S/N: {heat_sig:.1f} \"\n",
    "            f\"< threshold: {cfg['MIN_PEAK_SIGNIFICANCE']}). \"\n",
    "            \"Data may be too noisy or smoothing is wrong.\"\n",
    "        )\n",
    "        is_ok = False\n",
    "        \n",
    "    return is_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "code-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(\n",
    "    cooling_df: pd.DataFrame, \n",
    "    heating_df: pd.DataFrame,\n",
    "    analysis: dict,\n",
    "    output_path: Path\n",
    "):\n",
    "    \"\"\"Generates and saves a 4-panel analysis plot.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f\"Thermal Transformation Analysis: {output_path.parts[-3]}\", fontsize=18)\n",
    "    \n",
    "    Ms, M_peak, Mf = analysis['cooling']['temps']\n",
    "    As, A_peak, Af = analysis['heating']['temps']\n",
    "    cool_data = analysis['cooling']['plot_data']\n",
    "    heat_data = analysis['heating']['plot_data']\n",
    "\n",
    "    # --- Plot 1: PE Hysteresis ---\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(cooling_df['temp'], cooling_df['pe'], '.-', label='Cooling (A->M)', color='blue', alpha=0.7)\n",
    "    ax.plot(heating_df['temp'], heating_df['pe'], '.-', label='Heating (M->A)', color='red', alpha=0.7)\n",
    "    if not np.isnan(Ms):\n",
    "        ax.axvline(Ms, ls='--', color='blue', label=f'Ms: {Ms:.1f} K')\n",
    "        ax.axvline(Mf, ls=':', color='blue', label=f'Mf: {Mf:.1f} K')\n",
    "    if not np.isnan(As):\n",
    "        ax.axvline(As, ls='--', color='red', label=f'As: {As:.1f} K')\n",
    "        ax.axvline(Af, ls=':', color='red', label=f'Af: {Af:.1f} K')\n",
    "    ax.set_xlabel(\"Temperature (K)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Potential Energy (eV)\", fontsize=12)\n",
    "    ax.set_title(\"Potential Energy Hysteresis\", fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    # --- Plot 2: Volume Hysteresis ---\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(cooling_df['temp'], cooling_df['vol'], '.-', label='Cooling (A->M)', color='blue', alpha=0.7)\n",
    "    ax.plot(heating_df['temp'], heating_df['vol'], '.-', label='Heating (M->A)', color='red', alpha=0.7)\n",
    "    ax.set_xlabel(\"Temperature (K)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Volume (Å³)\", fontsize=12)\n",
    "    ax.set_title(\"Volume Hysteresis\", fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    # --- Plot 3: Cooling Derivative (d(PE)/dT) ---\n",
    "    ax = axes[1, 0]\n",
    "    if 'T' in cool_data:\n",
    "        ax.plot(cool_data['T'], cool_data['dPdT_smooth'], '-', color='blue', label='d(PE)/dT (smoothed)')\n",
    "        ax.axhline(cool_data['threshold'], ls=':', color='gray', label=f'{ANALYSIS_CONFIG[\"THRESHOLD_PERCENT\"]*100:.0f}% Threshold')\n",
    "        if not np.isnan(Ms):\n",
    "            ax.axvline(Ms, ls='--', color='k', label=f'Ms: {Ms:.1f} K')\n",
    "            ax.axvline(M_peak, ls='-', color='gray', label=f'Peak: {M_peak:.1f} K')\n",
    "            ax.axvline(Mf, ls=':', color='k', label=f'Mf: {Mf:.1f} K')\n",
    "        # Add S/N to plot\n",
    "        sig = cool_data.get('peak_significance', 0)\n",
    "        ax.text(0.05, 0.95, f\"Peak S/N: {sig:.1f}\", transform=ax.transAxes, \n",
    "                ha='left', va='top', bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.5))\n",
    "    ax.set_xlabel(\"Temperature (K)\", fontsize=12)\n",
    "    ax.set_ylabel(\"d(PE)/dT (eV/K)\", fontsize=12)\n",
    "    ax.set_title(\"Cooling Analysis (A → M)\", fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    # --- Plot 4: Heating Derivative (d(PE)/dT) ---\n",
    "    ax = axes[1, 1]\n",
    "    if 'T' in heat_data:\n",
    "        ax.plot(heat_data['T'], heat_data['dPdT_smooth'], '-', color='red', label='d(PE)/dT (smoothed)')\n",
    "        ax.axhline(heat_data['threshold'], ls=':', color='gray', label=f'{ANALYSIS_CONFIG[\"THRESHOLD_PERCENT\"]*100:.0f}% Threshold')\n",
    "        if not np.isnan(As):\n",
    "            ax.axvline(As, ls='--', color='k', label=f'As: {As:.1f} K')\n",
    "            ax.axvline(A_peak, ls='-', color='gray', label=f'Peak: {A_peak:.1f} K')\n",
    "            ax.axvline(Af, ls=':', color='k', label=f'Af: {Af:.1f} K')\n",
    "        # Add S/N to plot\n",
    "        sig = heat_data.get('peak_significance', 0)\n",
    "        ax.text(0.05, 0.95, f\"Peak S/N: {sig:.1f}\", transform=ax.transAxes, \n",
    "                ha='left', va='top', bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.5))\n",
    "    ax.set_xlabel(\"Temperature (K)\", fontsize=12)\n",
    "    ax.set_ylabel(\"d(PE)/dT (eV/K)\", fontsize=12)\n",
    "    ax.set_title(\"Heating Analysis (M → A)\", fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    save_path = output_path / \"transformation_analysis.png\"\n",
    "    plt.savefig(save_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(f\"     ✓ Saved analysis plot to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "code-save-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary(analysis: dict, analysis_ok: bool, errors: list, output_path: Path):\n",
    "    \"\"\"Saves the key temperature values and analysis status to a text file.\"\"\"\n",
    "    \n",
    "    Ms, M_peak, Mf = analysis['cooling']['temps']\n",
    "    As, A_peak, Af = analysis['heating']['temps']\n",
    "    \n",
    "    hysteresis_width = (Af - Ms) if not (np.isnan(Af) or np.isnan(Ms)) else np.nan\n",
    "    hysteresis_center_shift = (A_peak - M_peak) if not (np.isnan(A_peak) or np.isnan(M_peak)) else np.nan\n",
    "\n",
    "    summary_file = output_path / \"transformation_summary.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"# Thermal Transformation Analysis Summary\\n\")\n",
    "        f.write(f\"# Structure: {output_path.parts[-3]}\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        \n",
    "        ### NEW: Analysis Status ###\n",
    "        if analysis_ok:\n",
    "            f.write(\"ANALYSIS STATUS: [✓ OK] Automated checks passed.\\n\")\n",
    "        else:\n",
    "            f.write(\"ANALYSIS STATUS: [✗ FAILED] Automated checks failed.\\n\")\n",
    "            f.write(\"     REASONS:\\n\")\n",
    "            for i, err in enumerate(errors, 1):\n",
    "                f.write(f\"         {i}. {err}\\n\")\n",
    "            f.write(\"\\n     WARNING: Do NOT trust these values. \"\n",
    "                    \"Check 'transformation_analysis.png' and \"\n",
    "                    \"tune ANALYSIS_CONFIG parameters in the script.\\n\")\n",
    "                    \n",
    "        f.write(\"-\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"MARTENSITE TRANSFORMATION (COOLING)\\n\")\n",
    "        f.write(f\"   Ms (Start):    {Ms:.2f} K\\n\")\n",
    "        f.write(f\"   M_peak (Peak):  {M_peak:.2f} K\\n\")\n",
    "        f.write(f\"   Mf (Finish):   {Mf:.2f} K\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"AUSTENITE TRANSFORMATION (HEATING)\\n\")\n",
    "        f.write(f\"   As (Start):    {As:.2f} K\\n\")\n",
    "        f.write(f\"   A_peak (Peak):  {A_peak:.2f} K\\n\")\n",
    "        f.write(f\"   Af (Finish):   {Af:.2f} K\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"HYSTERESIS PROPERTIES\\n\")\n",
    "        f.write(f\"   Width (Af - Ms):         {hysteresis_width:.2f} K\\n\")\n",
    "        f.write(f\"   Peak Shift (A_peak - M_peak): {hysteresis_center_shift:.2f} K\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        \n",
    "        if analysis_ok:\n",
    "            f.write(\"\\nACTION REQUIRED:\\n\")\n",
    "            f.write(\"   Update 'sme_DEFORMATION_FIXED.lmp' with these values:\\n\")\n",
    "            # Provide a 20K safety margin\n",
    "            f.write(f\"   variable T_low  equal {Mf - 20.0:.1f}   # (Value below Mf: {Mf:.1f} K)\\n\")\n",
    "            f.write(f\"   variable T_high equal {Af + 20.0:.1f}   # (Value above Af: {Af:.1f} K)\\n\")\n",
    "        else:\n",
    "            f.write(\"\\nACTION REQUIRED:\\n\")\n",
    "            f.write(\"   Analysis failed. You must manually inspect the .png plot\\n\")\n",
    "            f.write(\"   and tune the 'ANALYSIS_CONFIG' parameters at the top\\n\")\n",
    "            f.write(\"   of this python script (analyze_thermal_cycle_v2.py).\\n\")\n",
    "            \n",
    "    print(f\"     ✓ Saved summary to {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "code-main",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" Main driver function. \"\"\"\n",
    "    print(\"==========================================\")\n",
    "    print(\"Running Thermal Cycle Analysis (v2)\")\n",
    "    print(f\"Searching for files in: {INPUT_DATA_ROOT}\")\n",
    "    print(\"==========================================\")\n",
    "    \n",
    "    ANALYSIS_OUTPUT_ROOT.mkdir(exist_ok=True)\n",
    "    thermo_files = list(INPUT_DATA_ROOT.glob(\"*/thermal_cycle/thermo_detailed.txt\"))\n",
    "    \n",
    "    if not thermo_files:\n",
    "        print(f\"Error: No 'thermo_detailed.txt' files found.\", file=sys.stderr)\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(thermo_files)} files to analyze...\")\n",
    "    \n",
    "    overall_success = True\n",
    "    for thermo_file in thermo_files:\n",
    "        structure_name = thermo_file.parts[-3]\n",
    "        print(f\"\\nProcessing: {structure_name}\")\n",
    "        \n",
    "        output_dir = ANALYSIS_OUTPUT_ROOT / structure_name / \"thermal_cycle\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df = load_data(thermo_file)\n",
    "        if df is None:\n",
    "            overall_success = False\n",
    "            continue\n",
    "            \n",
    "        cooling_df, heating_df = split_cycles(df)\n",
    "        if cooling_df.empty or heating_df.empty:\n",
    "            print(\"   [ERROR] Could not find both cooling and heating ramps. Skipping.\", file=sys.stderr)\n",
    "            overall_success = False\n",
    "            continue\n",
    "            \n",
    "        print(\"   Analyzing cooling ramp (A->M)...\")\n",
    "        Ms, M_peak, Mf, cool_data = analyze_transformation(cooling_df)\n",
    "        \n",
    "        print(\"   Analyzing heating ramp (M->A)...\")\n",
    "        As, A_peak, Af, heat_data = analyze_transformation(heating_df)\n",
    "        \n",
    "        analysis_results = {\n",
    "            \"cooling\": {\"temps\": (Ms, M_peak, Mf), \"plot_data\": cool_data},\n",
    "            \"heating\": {\"temps\": (As, A_peak, Af), \"plot_data\": heat_data}\n",
    "        }\n",
    "        \n",
    "        # --- 5. ### NEW ### Run Sanity Checks ---\n",
    "        print(\"   Running automated sanity checks...\")\n",
    "        analysis_errors = []\n",
    "        analysis_ok = run_sanity_checks(analysis_results, analysis_errors)\n",
    "        \n",
    "        if analysis_ok:\n",
    "            print(\"     [✓ ANALYSIS OK] All checks passed.\")\n",
    "        else:\n",
    "            print(f\"     [✗ ANALYSIS FAILED] {len(analysis_errors)} error(s) found:\")\n",
    "            for err in analysis_errors:\n",
    "                print(f\"       - {err}\")\n",
    "            overall_success = False\n",
    "\n",
    "        # --- 6. Plot Results (always, for debugging) ---\n",
    "        plot_results(cooling_df, heating_df, analysis_results, output_dir)\n",
    "        \n",
    "        # --- 7. Save Summary ---\n",
    "        save_summary(analysis_results, analysis_ok, analysis_errors, output_dir)\n",
    "\n",
    "    print(\"\\n==========================================\")\n",
    "    if overall_success:\n",
    "        print(\"✓ Analysis complete. All structures passed checks.\")\n",
    "    else:\n",
    "        print(\"! Analysis complete. One or more structures FAILED automated checks.\")\n",
    "        print(\"   Please review the 'transformation_summary.txt' and '.png' files\")\n",
    "        print(f\"   in {ANALYSIS_OUTPUT_ROOT} for the failed structures.\")\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-run-main",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Running Thermal Cycle Analysis (v2)\n",
      "Searching for files in: /home/rimuru/workspace/data/raw_output\n",
      "==========================================\n",
      "Found 1 files to analyze...\n",
      "\n",
      "Processing: niti_2nm_Ni50_amorphous\n",
      "   Analyzing cooling ramp (A->M)...\n",
      "   Analyzing heating ramp (M->A)...\n",
      "   Running automated sanity checks...\n",
      "     [✗ ANALYSIS FAILED] 1 error(s) found:\n",
      "       - Analysis routine failed (e.g., not enough data).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66368/2956071334.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "   [WARN] Not enough data points (5) for smoothing window (51). Skipping.\n",
      "   [WARN] Not enough data points (5) for smoothing window (51). Skipping.\n",
      "/tmp/ipykernel_66368/3420126734.py:57: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n",
      "/tmp/ipykernel_66368/3420126734.py:75: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ✓ Saved analysis plot to /home/rimuru/workspace/data/analysis_output/niti_2nm_Ni50_amorphous/thermal_cycle/transformation_analysis.png\n",
      "     ✓ Saved summary to /home/rimuru/workspace/data/analysis_output/niti_2nm_Ni50_amorphous/thermal_cycle/transformation_summary.txt\n",
      "\n",
      "==========================================\n",
      "! Analysis complete. One or more structures FAILED automated checks.\n",
      "   Please review the 'transformation_summary.txt' and '.png' files\n",
      "   in /home/rimuru/workspace/data/analysis_output for the failed structures.\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
